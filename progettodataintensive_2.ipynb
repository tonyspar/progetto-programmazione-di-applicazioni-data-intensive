{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # da commentare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cmd(cmd):\n",
    "    try:\n",
    "        subprocess.check_call(cmd, shell=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Command failed: {cmd}\\n{e}\")\n",
    "\n",
    "def install(package):\n",
    "    # Try pip first\n",
    "    try:\n",
    "        run_cmd(f\"{sys.executable} -m pip install --upgrade pip\")\n",
    "        run_cmd(f\"{sys.executable} -m pip install {package}\")\n",
    "    except Exception:\n",
    "        # Fallback for environments like Colab\n",
    "        run_cmd(f\"!pip install {package}\")\n",
    "\n",
    "# List of required packages\n",
    "packages = [\n",
    "    \"numpy<2.0,>=1.20\",\n",
    "    \"pandas\",\n",
    "    \"scikit-learn\",\n",
    "    \"matplotlib\",\n",
    "    \"scikit-surprise\",  # This is the correct package name for 'surprise'\n",
    "    \"jovian --upgrade --quiet\",\n",
    "    \"kaggle\",\n",
    "    \"numpy.typing\"\n",
    "]\n",
    "\n",
    "def is_conda():\n",
    "    try:\n",
    "        return hasattr(sys, 'base_prefix') and 'conda' in sys.version or 'Continuum' in sys.version\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def install(package):\n",
    "    if is_conda():\n",
    "        # Try installing with conda first\n",
    "        try:\n",
    "            run_cmd(f\"conda install -y {package.split()[0]}\")\n",
    "            return\n",
    "        except Exception:\n",
    "            pass\n",
    "    # Fallback to pip\n",
    "    try:\n",
    "        run_cmd(f\"{sys.executable} -m pip install --upgrade pip\")\n",
    "        run_cmd(f\"{sys.executable} -m pip install {package}\")\n",
    "    except Exception:\n",
    "        # Fallback for environments like Colab\n",
    "        run_cmd(f\"!pip install {package}\")\n",
    "\n",
    "# Uninstall numpy first to avoid version conflicts\n",
    "run_cmd(f\"{sys.executable} -m pip uninstall numpy -y\")\n",
    "\n",
    "for pkg in packages:\n",
    "    install(pkg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 1. Descrizione del problema e analisi esplorativa\n",
    "\n",
    " ### Caricamento Librerie\n",
    "\n",
    " Per prima cosa carichiamo le librerie per effettuare operazioni sui dati\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " NumPy per creare e operare su array a N dimensioni\n",
    "\n",
    "     pandas per caricare e manipolare dati tabulari\n",
    "\n",
    "     matplotlib per creare grafici\n",
    "\n",
    "\n",
    "\n",
    " Importiamo le librerie usando i loro alias convenzionali e abilitando l'inserimento dei grafici direttamente nel notebook\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "#import surprise\n",
    "import jovian\n",
    "from sklearn.datasets import fetch_openml\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NON RIESEGUIRE\n",
    "# if not os.path.exists(\"kaggle.json\") and not os.path.exists(\"~/.kaggle/kaggle.json\"):\n",
    "#     ! mkdir ~/.kaggle\n",
    "#     ! cp kaggle.json ~/.kaggle/\n",
    "#     ! chmod 600 ~/.kaggle/kaggle.json\n",
    "#     ! kaggle datasets list\n",
    "#     !kaggle datasets download antonkozyriev/game-recommendations-on-steam\n",
    "#     !mkdir games\n",
    "#     !unzip game-recommendations-on-steam.zip -d games_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getcwd())\n",
    "os.chdir(r\"C:\\Users\\manto\\Documents\\Università\\3°anno\\Data_intensive\\progetto-programmazione-di-applicazioni-data-intensive\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigdata=pd.read_csv(\"./games_dataset/games.csv\", index_col=0)\n",
    "bigdata['steam_deck'].value_counts()\n",
    "bigdata.drop(columns=[\"steam_deck\"], inplace=True);\n",
    "bigdata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## editing dataset dati aggiuntivi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Alcune feature non sono rilevanti per il nostro problema, possiamo quindi rimuovere le colonne dal dataframe per risparmiare ulteriormente spazio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# editing dataset dati aggiuntivi\n",
    "df = fetch_openml(data_id=43689)\n",
    "secdata = pd.DataFrame({\n",
    "    \"SteamURL\": df.data[\"SteamURL\"],\n",
    "    \"Metacritic\": df.data[\"Metacritic\"],\n",
    "    \"Platform\": df.data[\"Platform\"],\n",
    "    \"Tags\": df.data[\"Tags\"],\n",
    "    \"Languages\": df.data[\"Languages\"]\n",
    "})\n",
    "secdata=secdata.dropna(axis='rows', subset=[\"SteamURL\",\"Tags\"])\n",
    "secdata['SteamURL']=secdata['SteamURL'].str[35:-16]\n",
    "secdata.drop_duplicates(subset=['SteamURL'], inplace=True)\n",
    "secdata['SteamURL']=secdata['SteamURL'].astype('int64')\n",
    "secdata.index=secdata['SteamURL']\n",
    "secdata.drop(columns='SteamURL', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# editing dataset tag\n",
    "metadata = pd.read_json(\"games_dataset/games_metadata.json\", lines=\"True\")\n",
    "metadata.to_csv(\"data3.csv\", encoding='utf-8', index=False)\n",
    "tagsdata = pd.read_csv(\"data3.csv\", index_col=0)\n",
    "tagsdata=tagsdata.drop(columns='description')\n",
    "tagsdata.drop(tagsdata[tagsdata['tags'].str.len()==2].index, inplace=True)\n",
    "tagsdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rank_stats(value):\n",
    "    if str(value).lower() == 'true':\n",
    "        return random.randint(3, 5)\n",
    "    else:\n",
    "        return random.randint(1, 2)\n",
    "\n",
    "rec_data = pd.read_csv(\"games_dataset/recommendations.csv\", index_col=0,sep=';')\n",
    "rec_data['is_recommended'] = rec_data['is_recommended'].map(rank_stats)\n",
    "rec_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dei dataset\n",
    "tempdata=pd.merge(how='left', left=bigdata, right=secdata, left_index=True, right_index=True)\n",
    "data=pd.merge(how='left', left=tempdata, right=tagsdata, left_index=True, right_index=True)\n",
    "data=pd.merge(how='left', left=data, right=rec_data, left_index=True, right_index=True)\n",
    "data.drop(columns='Tags', inplace=True)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "matrice.notna()\n",
    "\n",
    "Nello specifico, le features disponibile (come si può osservare dalla rappresentazione del dataset) sono:\n",
    "\n",
    " Age | Objective Feature | age | int (days)\n",
    "\n",
    " Height | Objective Feature | height | int (cm) |\n",
    "\n",
    " Weight | Objective Feature | weight | float (kg) |\n",
    "\n",
    " Gender | Objective Feature | gender | categorical code |\n",
    "\n",
    " Systolic blood pressure | Examination Feature | ap_hi | int |\n",
    "\n",
    " Diastolic blood pressure | Examination Feature | ap_lo | int |\n",
    "\n",
    " Cholesterol | Examination Feature | cholesterol | 1: normal, 2: above normal, 3: well above normal |\n",
    "\n",
    " Glucose | Examination Feature | gluc | 1: normal, 2: above normal, 3: well above normal |\n",
    "\n",
    " Smoking | Subjective Feature | smoke | binary |\n",
    "\n",
    " Alcohol intake | Subjective Feature | alco | binary |\n",
    "\n",
    " Physical activity | Subjective Feature | active | binary |\n",
    "\n",
    " Presence or absence of cardiovascular disease | Target Variable | cardio | binary |\n",
    "\n",
    "dataset['cardio'].value_counts().plot.pie(autopct='%1.1f%%')\n",
    "\n",
    "Rilevazione di valori nulli"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
